{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PinkOrangeSapphire/229352/blob/main/Lab04_Naive_Bayes_Grid_and_Random_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9252fd0-8fb3-4237-a32c-d2ae904aeba1",
      "metadata": {
        "id": "e9252fd0-8fb3-4237-a32c-d2ae904aeba1"
      },
      "source": [
        "### Statistical Learning for Data Science 2 (229352)\n",
        "#### Instructor: Donlapark Ponnoprat\n",
        "\n",
        "#### [Course website](https://donlapark.pages.dev/229352/)\n",
        "\n",
        "## Lab #4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "70b30d42-2935-4d97-afb4-51b444e01360",
      "metadata": {
        "id": "70b30d42-2935-4d97-afb4-51b444e01360"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from scipy.stats import uniform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b4116b7d-ca3e-4e82-8452-ec6b220bb328",
      "metadata": {
        "id": "b4116b7d-ca3e-4e82-8452-ec6b220bb328",
        "outputId": "efa28662-c000-4cc4-a0e0-90c95c84bec7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: 500\n",
            "y: 500\n"
          ]
        }
      ],
      "source": [
        "train = fetch_20newsgroups(subset='train')\n",
        "test = fetch_20newsgroups(subset='test')\n",
        "\n",
        "Xtrain = train.data[:3000]\n",
        "ytrain = train.target[:3000]\n",
        "Xtest = test.data[:500]\n",
        "ytest = test.target[:500]\n",
        "\n",
        "print(\"X:\", len(Xtest))\n",
        "print(\"y:\", len(ytest))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "452ca0da-2658-4daa-85be-d42ea298fe07",
      "metadata": {
        "id": "452ca0da-2658-4daa-85be-d42ea298fe07"
      },
      "source": [
        "### Naive Bayes [(Documentation)](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1a2cb016-1e96-44e8-8c64-823ad825afd9",
      "metadata": {
        "id": "1a2cb016-1e96-44e8-8c64-823ad825afd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd72b777-f95e-47fc-fa90-a14ac949d738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.38      0.48        21\n",
            "           1       0.79      0.52      0.63        21\n",
            "           2       0.58      0.69      0.63        26\n",
            "           3       0.74      0.68      0.71        34\n",
            "           4       0.72      0.85      0.78        34\n",
            "           5       0.88      0.81      0.84        26\n",
            "           6       1.00      0.73      0.84        22\n",
            "           7       0.70      1.00      0.82        28\n",
            "           8       0.90      0.82      0.86        33\n",
            "           9       0.88      0.84      0.86        25\n",
            "          10       0.82      1.00      0.90        27\n",
            "          11       0.79      0.95      0.86        20\n",
            "          12       0.59      0.54      0.57        24\n",
            "          13       0.75      0.78      0.77        23\n",
            "          14       0.87      0.71      0.78        28\n",
            "          15       0.53      0.90      0.67        29\n",
            "          16       0.50      0.95      0.66        21\n",
            "          17       0.94      0.83      0.88        18\n",
            "          18       0.86      0.23      0.36        26\n",
            "          19       0.00      0.00      0.00        14\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.72      0.71      0.70       500\n",
            "weighted avg       0.74      0.73      0.71       500\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
        "    ('nb', MultinomialNB())\n",
        "])\n",
        "pipeline.fit(Xtrain, ytrain)\n",
        "ypred = pipeline.predict(Xtest)\n",
        "print(classification_report(ytest, ypred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90fe0d6a-bb47-40ba-8660-c1af8f35eeb9",
      "metadata": {
        "id": "90fe0d6a-bb47-40ba-8660-c1af8f35eeb9"
      },
      "source": [
        "### Random Search Cross-Validation [(Documentation)](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
        "\n",
        "### Uniform distribution in `Scipy` [(Documentation)](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.uniform.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "73f44229-8e90-40ad-b1e7-827597dba207",
      "metadata": {
        "id": "73f44229-8e90-40ad-b1e7-827597dba207",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20aaa0ba-563c-432e-a8fb-f1d9ebf5a175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.38      0.50        21\n",
            "           1       0.91      0.48      0.62        21\n",
            "           2       0.56      0.73      0.63        26\n",
            "           3       0.72      0.62      0.67        34\n",
            "           4       0.66      0.85      0.74        34\n",
            "           5       0.88      0.85      0.86        26\n",
            "           6       1.00      0.64      0.78        22\n",
            "           7       0.61      1.00      0.76        28\n",
            "           8       0.90      0.82      0.86        33\n",
            "           9       0.88      0.84      0.86        25\n",
            "          10       0.82      1.00      0.90        27\n",
            "          11       0.86      0.95      0.90        20\n",
            "          12       0.57      0.54      0.55        24\n",
            "          13       0.74      0.74      0.74        23\n",
            "          14       0.90      0.68      0.78        28\n",
            "          15       0.51      0.90      0.65        29\n",
            "          16       0.49      0.90      0.63        21\n",
            "          17       0.93      0.78      0.85        18\n",
            "          18       1.00      0.19      0.32        26\n",
            "          19       0.00      0.00      0.00        14\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.73      0.69      0.68       500\n",
            "weighted avg       0.74      0.72      0.70       500\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "parameter = {'nb__alpha': uniform(loc=0, scale=10)}\n",
        "clf = RandomizedSearchCV(pipeline, parameter, n_iter=10) #10rng\n",
        "clf.fit(Xtrain, ytrain)\n",
        "ypred = clf.predict(Xtest)\n",
        "print(classification_report(ytest, ypred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74f7ad65-0b56-4987-9493-c5f06a7f481b",
      "metadata": {
        "id": "74f7ad65-0b56-4987-9493-c5f06a7f481b"
      },
      "source": [
        "#### Exercise\n",
        "\n",
        "1. For the Naive Bayes model, use grid search 5-fold cross-validation across different values of `alpha` to find the best model.\n",
        "\n",
        "2. For the best value of `alpha`, compute the `f1_macro` score on the test set.\n",
        "* What value of `alpha` did you obtain?\n",
        "* What is the model's `f1_macro` score?\n",
        "\n",
        "3. Repeat Exercise 1 and 2 for **random search** 5-fold cross validation across different values of `alpha`. Compute the `f1_macro` score on the test set.\n",
        "* What value of `alpha` did you obtain?\n",
        "* Did you get a better `f1_macro` score compared to grid search in Exercise 2?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c0eba91",
        "outputId": "e61df20e-b9b4-472a-cb28-590ebb63fa16"
      },
      "source": [
        "param_grid = {'nb__alpha': [0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Instantiate GridSearchCV\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1_macro')\n",
        "\n",
        "# Fit GridSearchCV to the training data\n",
        "grid_search.fit(Xtrain, ytrain)\n",
        "\n",
        "print(\"Grid Search completed <333\")"
      ],
      "id": "9c0eba91",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid Search completed <333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4500912f",
        "outputId": "8a36dafc-02e6-41c3-f568-c7b0c22b8847"
      },
      "source": [
        "print(f\"Best alpha value: {grid_search.best_params_['nb__alpha']}\")\n",
        "\n",
        "best_grid_model = grid_search.best_estimator_\n",
        "ypred_grid = best_grid_model.predict(Xtest)\n",
        "\n",
        "# Calculate f1_macro score\n",
        "from sklearn.metrics import f1_score\n",
        "f1_macro_grid = f1_score(ytest, ypred_grid, average='macro')\n",
        "\n",
        "print(f\"Model's f1_macro score on test set: {f1_macro_grid}\")"
      ],
      "id": "4500912f",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best alpha value: 0.01\n",
            "Model's f1_macro score on test set: 0.7708784080844321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da26878c",
        "outputId": "50599634-234d-41de-af90-ef8b74755b9f"
      },
      "source": [
        "parameter_dist = {'nb__alpha': uniform(loc=0, scale=10)}\n",
        "\n",
        "# Instantiate RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(pipeline, parameter_dist, n_iter=10, cv=5, scoring='f1_macro')\n",
        "\n",
        "# Fit RandomizedSearchCV to the training data\n",
        "random_search.fit(Xtrain, ytrain)\n",
        "\n",
        "print(\"Random Search completed.\")"
      ],
      "id": "da26878c",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Search completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9db6e54",
        "outputId": "563ff8b6-5b45-4a8d-f711-c7e2804ea64d"
      },
      "source": [
        "print(f\"Best alpha value (Random Search): {random_search.best_params_['nb__alpha']}\")\n",
        "\n",
        "best_random_model = random_search.best_estimator_\n",
        "ypred_random = best_random_model.predict(Xtest)\n",
        "\n",
        "f1_macro_random = f1_score(ytest, ypred_random, average='macro')\n",
        "\n",
        "print(f\"Model's f1_macro score on test set (Random Search): {f1_macro_random}\")\n",
        "print(f\"f1_macro score from Grid Search: {f1_macro_grid}\")\n",
        "\n",
        "if f1_macro_random > f1_macro_grid:\n",
        "    print(\"Random search yielded a better f1_macro score.\")\n",
        "elif f1_macro_random < f1_macro_grid:\n",
        "    print(\"Grid search yielded a better f1_macro score.\")\n",
        "else:\n",
        "    print(\"Both grid search and random search yielded the same f1_macro score.\")"
      ],
      "id": "b9db6e54",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best alpha value (Random Search): 1.5544266668627293\n",
            "Model's f1_macro score on test set (Random Search): 0.6801380191485173\n",
            "f1_macro score from Grid Search: 0.7708784080844321\n",
            "Grid search yielded a better f1_macro score.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}